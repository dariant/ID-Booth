# ID-Booth: Identity-consistent Face Generation with Diffusion Models

<div align="center">
  Darian Toma≈°eviƒá, Fadi Boutros, Chenhao Lin, Naser Damer, Peter Peer, Vitomir ≈†truc
  <br>
  <br>
  <a href='https://arxiv.org/abs/2403.11641'><img src='https://img.shields.io/badge/Paper-arXiv-red'></a>
  <br>
  <br>
</div>  
<div align="center">
        
</div>
This is the official implementation of the ID-Booth framework, which:

&emsp;üî• generates in-the-wild images of consenting identities captured in a constrained environment <br>
&emsp;üî• uses a triplet identity loss to fine-tune Stable Diffusion for identity-consistent yet diverse image generation <br>
&emsp;üî• can augment small-scale datasets to improve their suitability for training face recognition models  <br>
<br>

<div align="center">
  <p>
    <img width="80%" src="./assets/preview_samples.jpg">
  </p>
</div>


## <div align="center"> Installation </div>

```bash
conda create -n id-booth python=3.10
conda activate id-booth
pip install -r requirements.txt
```

## <div align="center"> Dowload links for pretrained models </div>

To generate images of identities found in the paper, download their fine-tuned [ID-Booth LoRA weights](https://unilj-my.sharepoint.com/:u:/g/personal/darian_tomasevic_fri1_uni-lj_si/ET2lpGwcIjlNhZEBnYxPDwYBgGcVl08rrXJvY4U3t3KWMg?e=Vjahfd).
To create your own fine-tuned model with ID-Booth, download the pretrained [ArcFace recognition model](https://unilj-my.sharepoint.com/:u:/g/personal/darian_tomasevic_fri1_uni-lj_si/EfSmDfvsVlZEuOBqieDl4zEBJkTJ65aBnUtrC4q5nT2a-g?e=PBYj7o), and place the weights into the [ArcFace_files](https://github.com/dariant/ID-Booth/tree/main/ArcFace_files) directory.



## <div align="center"> Generating identity-specific images </div>

To generate images of a desired identity with [Stable Diffusion 2.1](https://huggingface.co/stabilityai/stable-diffusion-2-1), use the [diffusers](https://huggingface.co/docs/diffusers/index) library to load the corresponding LoRA weights, which were trained with the ID-Booth framework. The following example generates in-the-wild images of ID_1: 

```python
import torch
from diffusers import StableDiffusionPipeline, DDPMScheduler

base_model = "stabilityai/stable-diffusion-2-1-base"
lora_checkpoint =  "trained_lora_models/ID_1/checkpoint-31-6400" # Download or train your own

prompt = "face portrait photo of male sks person, city street background"
negative_prompt = "cartoon, render, illustration, painting, drawing, black and white, bad body proportions, landscape"         

pipe = StableDiffusionPipeline.from_pretrained(base_model, torch_dtype=torch.float16).to("cuda:0")      
pipe.scheduler = DDPMScheduler.from_pretrained(base_model, subfolder="scheduler")
pipe.load_lora_weights(lora_checkpoint)
               
image = pipe(prompt=prompt,
              negative_prompt=negative_prompt,
              num_inference_steps=30,
              guidance_scale=5.0).images[0]

image.save(f"ID_1_{prompt}.png")
```
Results in the paper can be reproduced with data generated by the [inference_ID-Booth.py](https://github.com/dariant/ID-Booth/blob/main/inference_ID-Booth.py) script.



## <div align="center"> ID-Booth fine-tuning on new identities </div>

To perform ID-Booth fine-tuning of [Stable Diffusion 2.1](https://huggingface.co/stabilityai/stable-diffusion-2-1) on a new identity, you can follow the [train_ID-Booth.py](https://github.com/dariant/ID-Booth/blob/main/train_ID-Booth.py) script. The training dataset for a desired identity should include a handful of images along with ID embeddings extracted from these images with a pretrained ArcFace recognition model:
```
FACE_DATASET
‚îî‚îÄ‚îÄ‚îÄ ID_1
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ images
‚îÇ   |       sample_0.png
‚îÇ   |       sample_1.png
‚îÇ   |       ...
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ ArcFace_embeds
‚îÇ           sample_0.pt
‚îÇ           sample_1.pt
‚îÇ           ...
‚îî‚îÄ‚îÄ‚îÄ ID_2
‚îî‚îÄ‚îÄ‚îÄ ...
```
The required ID embeddings can be extracted with the [extract_ArcFace_embeds.py](https://github.com/dariant/ID-Booth/blob/main/extract_ArcFace_embeds.py) script. 

To run the script ... specify the path to the directory with identity images ...
... Path specified in the [config_train_SD21.py](https://github.com/dariant/ID-Booth/blob/main/configs/config_train_SD21.py) file.


<div align="center">
  <p>
    <img width="80%" src="./assets/preview_framework.jpg">
  </p>
</div>


## Evaluation 
The experiments of the ID-Booth paper ... consist of three main parts. 

To evaluate the quality, fidelity and diversity of generated images, we rely on the following repositories:


Evaluation of quality and diversity is .. notebooks found in directories ". 

Notebooks and scripts for the experiments can also be found in the Evaluation directory. 


```
TODO
```



## Citation

If you use the code or results from this repository, please cite the ID-Booth paper:

```
TODO Add reference
```

## Acknowledgements

Supported in parts by the Slovenian Research and Innovation Agency ARIS through the Research Programmes P2-0250(B) "Metrology and Biometric Systems" and P2--0214 (A) ‚ÄúComputer Vision‚Äù, the ARIS Project J2-2501(A) "DeepBeauty" and the ARIS Young Researcher Program.

<img src="./docs/ARIS_logo_eng_resized.jpg" alt="ARIS_logo_eng_resized" width="400"/>



